---
# This file has the global overrides, that MUST be changed per cluster. More
# variables are in ansible/group_vars. ;)

################
# SRC          #
################
#ceph_repository:       <CHANGE ME> # where to find the ceph code 
#ceph_docker_version:   <CHANGE ME> # version of the image (e.g., latest)
#ceph_docker_username:  <CHANGE ME> # name of the user (e.g., ceph)
#ceph_docker_imagename: <CHANGE ME> # name of the image (e.g., daemon)
#ceph_wait_status:      <CHANGE ME> # string that indicates cluster is good

## uncomment for msevilla's cluster
#ceph_repository: https://github.com/michaelsevilla/ceph.git
#ceph_docker_version: f91680128ef51a85d28019c9afd29109bd178b1c
#ceph_docker_username: michaelsevilla
#ceph_docker_imagename: cephdaemon
#ceph_wait_status: "HEALTH_OK"
#cloudlab: false

## uncomment for singlenode
#ceph_wait_status: "HEALTH_WARN"
#cloudlab: false

# uncomment for cloudlab
ceph_repository: https://github.com/michaelsevilla/ceph.git
ceph_docker_version: a241c6f
ceph_docker_username: michaelsevilla
ceph_docker_imagename: ceph
ceph_wait_status: "HEALTH_OK"
cloudlab: true
kraken: false

################
# MON          #
################
#monitor_interface:         <CHANGE ME> # for these, see ceph-ansible repo
#ceph_mon_docker_interface: <CHANGE ME>
#ceph_mon_docker_subnet:    <CHANGE ME>

## uncomment for msevilla's cluster
#monitor_interface: eth1
#ceph_mon_docker_interface: eth1
#ceph_mon_docker_subnet: 192.168.140.0/24

# uncomment for cloudlab
monitor_interface: eth1
ceph_mon_docker_interface: eth1
ceph_mon_docker_subnet: 10.10.1.1
cluster_network: 10.10.1.0/24
#public_network: 128.104.222.0/22
public_network: 10.10.1.0/24

################
# OSD          #
################
#ceph_pgs: <CHANGE ME> # how many placement groups to add

## uncomment for msevilla's cluster
#ceph_pgs: [128]

## uncomment for singlenode
#ceph_pgs: [8]

## uncomment for cloudlab
ceph_pgs: [64, 128]

#<CHANGE ME> # select one of the below scenarios

# uncomment to use a real disk (for msevilla's cluster/cloudlab)
ceph_osd_docker_extra_env: "CEPH_DAEMON=OSD_CEPH_DISK_ACTIVATE"
ceph_osd_docker_prepare_env: "CEPH_DAEMON=OSD_CEPH_DISK_PREPARE,OSD_FORCE_ZAP=1"
ceph_osd_docker_devices:
 - /dev/sdc
osd_data_size: 400

## uncomment to use a directory (for singlenode)
#ceph_osd_docker_extra_env: "DUMMY=DUMMY"
#osd_directory: true

##############
# MDS        #
##############
#mount_point: <CHANGE ME> # where CephFS should mount

# uncomment for all clusters
mount_point: "/cephfs-baseliner"

####################
# experiment stuff #
####################
#repetitions:         <CHANGE ME> # how many times the experiment should run
#ceph_radosbench_cmd: <CHANGE ME> # how to benchmark the RADOS cluster

## uncomment for singlnode
#ceph_radosbench_cmd: "rados -p cephfs_metadata bench --show-time 5 write"
#repetitions: 1

## uncomment for multinode
ceph_radosbench_cmd: "rados -p cephfs_metadata bench --show-time 120 write"
repetitions: 3
root_file: "2AC36403-8E7E-E711-A599-02163E01366D.root"
root_src:  "/mnt/disk/root"
write_ext4: "/etc/ceph"


